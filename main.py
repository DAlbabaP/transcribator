"""
Transcribator - –õ–æ–∫–∞–ª—å–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ç–æ—Ä –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python main.py input.mp3 --output-dir ./output --formats text json srt
"""

import argparse
import os
import sys
import time
from pathlib import Path
from typing import List, Optional
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ç–æ—Ä–∞
from src.audio_processor import AudioProcessor
from src.transcriber import WhisperTranscriber
from src.diarizer import SpeakerDiarizer
from src.merger import TranscriptionMerger
from src.exporters.text_exporter import export_to_text
from src.exporters.json_exporter import export_to_json
from src.exporters.srt_exporter import export_to_srt, export_to_vtt


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    load_dotenv()
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    parser = create_argument_parser()
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if not os.path.exists(args.input_file):
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.input_file}")
        sys.exit(1)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    input_filename = Path(args.input_file).stem
    
    print("=" * 80)
    print("TRANSCRIBATOR - –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤")
    print("=" * 80)
    print(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {args.input_file}")
    print(f"–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {args.output_dir}")
    print(f"–ú–æ–¥–µ–ª—å Whisper: {args.model}")
    print(f"–Ø–∑—ã–∫: {args.language}")
    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {args.device}")
    print(f"–§–æ—Ä–º–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∞: {', '.join(args.formats)}")
    print("=" * 80)
    
    start_time = time.time()
    
    try:
        # –®–∞–≥ 1: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ
        print("\n" + "="*80)
        print("[1/5] –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –ê–£–î–ò–û")
        print("="*80)
        processor = AudioProcessor()
        processed_audio = processor.preprocess_audio(args.input_file)
        audio_duration = processor.get_audio_duration(processed_audio)
        print(f"‚úì –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"  ‚îî‚îÄ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {audio_duration:.2f} —Å–µ–∫ ({audio_duration/60:.1f} –º–∏–Ω)")
        print(f"  ‚îî‚îÄ –§–æ—Ä–º–∞—Ç: WAV 16kHz –º–æ–Ω–æ")
        
        # –®–∞–≥ 2: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
        print("\n" + "="*80)
        print(f"[2/5] –¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–Ø (–º–æ–¥–µ–ª—å: {args.model})")
        print("="*80)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
        cpu_count = os.cpu_count() or 4
        cpu_threads = args.cpu_threads if args.cpu_threads > 0 else cpu_count
        num_workers = args.num_workers if args.num_workers > 0 else min(4, cpu_count)
        
        print(f"‚öôÔ∏è  –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è CPU:")
        print(f"  ‚îî‚îÄ –î–æ—Å—Ç—É–ø–Ω–æ —è–¥–µ—Ä: {cpu_count}")
        print(f"  ‚îî‚îÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Ç–æ–∫–æ–≤: {cpu_threads}")
        print(f"  ‚îî‚îÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤: {num_workers}")
        print()
        
        transcriber = WhisperTranscriber(
            model_size=args.model,
            device=args.device,
            compute_type=args.compute_type,
            cpu_threads=cpu_threads,
            num_workers=num_workers
        )
        transcription_segments = transcriber.transcribe(
            processed_audio,
            language=args.language,
            vad_filter=args.vad_filter
        )
        print(f"\n‚úì –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"  ‚îî‚îÄ –ü–æ–ª—É—á–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(transcription_segments)}")
        print(f"  ‚îî‚îÄ –û–±—â–µ–µ –≤—Ä–µ–º—è —Ç–µ–∫—Å—Ç–∞: {sum(s.end - s.start for s in transcription_segments):.1f} —Å–µ–∫")
        
        # –®–∞–≥ 3: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        diarization_segments = None
        if not args.no_diarization:
            print("\n" + "="*80)
            print("[3/5] –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–ü–ò–ö–ï–†–û–í")
            print("="*80)
            
            # –ü–æ–ª—É—á–∞–µ–º HuggingFace —Ç–æ–∫–µ–Ω
            hf_token = args.hf_token or os.getenv('HF_TOKEN')
            if not hf_token or hf_token == 'your_huggingface_token_here':
                print("–û—à–∏–±–∫–∞: –Ω–µ —É–∫–∞–∑–∞–Ω HuggingFace —Ç–æ–∫–µ–Ω!")
                print("–£–∫–∞–∂–∏—Ç–µ —Ç–æ–∫–µ–Ω —á–µ—Ä–µ–∑ --hf-token –∏–ª–∏ –≤ .env —Ñ–∞–π–ª–µ (HF_TOKEN)")
                print("–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω:")
                print("1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ https://huggingface.co")
                print("2. –°–æ–∑–¥–∞–π—Ç–µ —Ç–æ–∫–µ–Ω: https://huggingface.co/settings/tokens")
                print("3. –ü—Ä–∏–º–∏—Ç–µ –ª–∏—Ü–µ–Ω–∑–∏–∏ –º–æ–¥–µ–ª–µ–π:")
                print("   - https://huggingface.co/pyannote/speaker-diarization-3.1")
                print("   - https://huggingface.co/pyannote/segmentation-3.0")
                sys.exit(1)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è diarization –µ—Å–ª–∏ GPU –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
            # (–Ω–∞–ø—Ä–∏–º–µ—Ä, RTX 5060 Ti —Å sm_120 –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è PyTorch 2.5.1)
            diarizer_device = args.device
            if args.device == 'cuda':
                import torch
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É GPU –¥–ª—è pyannote.audio
                if torch.cuda.is_available():
                    device_capability = torch.cuda.get_device_capability(0)
                    # sm_120 –∏ –Ω–æ–≤–µ–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è PyTorch 2.5.1
                    if device_capability[0] >= 12:
                        print(f"‚ö†Ô∏è  GPU –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ sm_{device_capability[0]}{device_capability[1]} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è PyTorch")
                        print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ (—Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –Ω–∞ GPU —Ä–∞–±–æ—Ç–∞–µ—Ç)")
                        diarizer_device = 'cpu'
            
            diarizer = SpeakerDiarizer(hf_token=hf_token, device=diarizer_device)
            diarization_segments = diarizer.diarize(
                processed_audio,
                num_speakers=args.num_speakers,
                min_speakers=args.min_speakers,
                max_speakers=args.max_speakers
            )
        else:
            print("\n" + "="*80)
            print("[3/5] –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–ü–ò–ö–ï–†–û–í - –ü–†–û–ü–£–©–ï–ù–û")
            print("="*80)
            print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä --no-diarization")
        
        # –®–∞–≥ 4: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\n" + "="*80)
        print("[4/5] –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("="*80)
        if diarization_segments:
            print("üîó –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å–æ —Å–ø–∏–∫–µ—Ä–∞–º–∏...")
            merger = TranscriptionMerger(min_overlap_ratio=args.min_overlap)
            merged_segments = merger.merge(transcription_segments, diarization_segments)
            stats = merger.get_statistics(merged_segments)
            print(f"\n‚úì –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            print(f"  ‚îî‚îÄ –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(merged_segments)}")
            print(f"  ‚îî‚îÄ –°–ø–∏–∫–µ—Ä–æ–≤: {stats['num_speakers']}")
            if stats['unknown_segments'] > 0:
                print(f"  ‚îî‚îÄ ‚ö†Ô∏è  –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {stats['unknown_segments']}")
        else:
            # –ë–µ–∑ diarization - –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            from src.merger import MergedSegment
            merged_segments = [
                MergedSegment(
                    start=seg.start,
                    end=seg.end,
                    text=seg.text,
                    speaker='SPEAKER_00',
                    confidence=1.0
                )
                for seg in transcription_segments
            ]
            print(f"‚úì –°–µ–≥–º–µ–Ω—Ç–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {len(merged_segments)}")
        
        # –®–∞–≥ 5: –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\n" + "="*80)
        print("[5/5] –≠–ö–°–ü–û–†–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("="*80)
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        metadata = {
            'source_file': os.path.basename(args.input_file),
            'model': args.model,
            'language': args.language,
            'duration': audio_duration,
            'diarization_enabled': not args.no_diarization
        }
        
        exported_files = []
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
        if 'text' in args.formats or 'all' in args.formats:
            text_file = output_dir / f"{input_filename}.txt"
            export_to_text(
                merged_segments,
                str(text_file),
                show_confidence=args.show_confidence,
                group_by_speaker=True
            )
            exported_files.append(str(text_file))
        
        if 'json' in args.formats or 'all' in args.formats:
            json_file = output_dir / f"{input_filename}.json"
            export_to_json(
                merged_segments,
                str(json_file),
                metadata=metadata,
                pretty=True
            )
            exported_files.append(str(json_file))
        
        if 'srt' in args.formats or 'all' in args.formats:
            srt_file = output_dir / f"{input_filename}.srt"
            export_to_srt(
                merged_segments,
                str(srt_file),
                include_speakers=not args.no_diarization
            )
            exported_files.append(str(srt_file))
        
        if 'vtt' in args.formats or 'all' in args.formats:
            vtt_file = output_dir / f"{input_filename}.vtt"
            export_to_vtt(
                merged_segments,
                str(vtt_file),
                include_speakers=not args.no_diarization
            )
            exported_files.append(str(vtt_file))
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω
        if processed_audio != args.input_file:
            try:
                os.remove(processed_audio)
            except:
                pass
        
        # –ò—Ç–æ–≥–∏
        elapsed_time = time.time() - start_time
        print("\n" + "=" * 80)
        print("‚úì –¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
        print("=" * 80)
        print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥ ({elapsed_time/60:.1f} –º–∏–Ω—É—Ç)")
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∞—É–¥–∏–æ: {audio_duration:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏: {audio_duration/elapsed_time:.2f}x —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏")
        print(f"\n–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        for file_path in exported_files:
            print(f"  - {file_path}")
        print("=" * 80)
        
    except KeyboardInterrupt:
        print("\n\n–û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n–û—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def create_argument_parser() -> argparse.ArgumentParser:
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    
    parser = argparse.ArgumentParser(
        description='Transcribator - –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
  python main.py audio.mp3

  # –° —É–∫–∞–∑–∞–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∞ –∏ –º–æ–¥–µ–ª–∏
  python main.py audio.mp3 --model medium --formats json srt

  # –ë–µ–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤
  python main.py audio.mp3 --no-diarization

  # –° —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ø–∏–∫–µ—Ä–æ–≤
  python main.py audio.mp3 --num-speakers 3

  # –î–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
  python main.py audio.mp3 --language en

–ë–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: https://github.com/yourusername/transcribator
        """
    )
    
    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    parser.add_argument(
        'input_file',
        type=str,
        help='–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –∞—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É'
    )
    
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    parser.add_argument(
        '--output-dir',
        type=str,
        default='./output',
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ./output)'
    )
    
    parser.add_argument(
        '--formats',
        nargs='+',
        choices=['text', 'json', 'srt', 'vtt', 'all'],
        default=['all'],
        help='–§–æ—Ä–º–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: all)'
    )
    
    parser.add_argument(
        '--model',
        type=str,
        choices=['tiny', 'base', 'small', 'medium', 'large-v2', 'large-v3'],
        default=os.getenv('WHISPER_MODEL', 'small'),
        help='–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ Whisper (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: small)'
    )
    
    parser.add_argument(
        '--language',
        type=str,
        default=os.getenv('DEFAULT_LANGUAGE', 'ru'),
        help='–Ø–∑—ã–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ru)'
    )
    
    parser.add_argument(
        '--device',
        type=str,
        choices=['cpu', 'cuda'],
        default='cpu',
        help='–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: cpu)'
    )
    
    parser.add_argument(
        '--compute-type',
        type=str,
        choices=['int8', 'float16', 'float32'],
        default='int8',
        help='–¢–∏–ø –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (int8 –¥–ª—è CPU, float16 –¥–ª—è GPU)'
    )
    
    parser.add_argument(
        '--cpu-threads',
        type=int,
        default=0,
        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ CPU (0 = –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ)'
    )
    
    parser.add_argument(
        '--num-workers',
        type=int,
        default=0,
        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤ (0 = –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)'
    )
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã diarization
    parser.add_argument(
        '--no-diarization',
        action='store_true',
        help='–û—Ç–∫–ª—é—á–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤'
    )
    
    parser.add_argument(
        '--num-speakers',
        type=int,
        default=None,
        help='–¢–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)'
    )
    
    parser.add_argument(
        '--min-speakers',
        type=int,
        default=None,
        help='–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)'
    )
    
    parser.add_argument(
        '--max-speakers',
        type=int,
        default=None,
        help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)'
    )
    
    parser.add_argument(
        '--hf-token',
        type=str,
        default=None,
        help='HuggingFace access token (–∏–ª–∏ —á–µ—Ä–µ–∑ HF_TOKEN –≤ .env)'
    )
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument(
        '--min-overlap',
        type=float,
        default=0.5,
        help='–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –¥–ª—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–∞ (0.0-1.0)'
    )
    
    parser.add_argument(
        '--vad-filter',
        action='store_true',
        default=True,
        help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Voice Activity Detection'
    )
    
    parser.add_argument(
        '--show-confidence',
        action='store_true',
        help='–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —ç–∫—Å–ø–æ—Ä—Ç–µ'
    )
    
    parser.add_argument(
        '--version',
        action='version',
        version='Transcribator 0.1.0'
    )
    
    return parser


if __name__ == '__main__':
    main()
