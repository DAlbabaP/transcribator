"""
–ú–æ–¥—É–ª—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ (Speaker Diarization) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º pyannote.audio

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:
- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pyannote.audio pipeline
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ø–∏–∫–µ—Ä–æ–≤ –∏ –∏—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
- –í–æ–∑–≤—Ä–∞—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å–æ —Å–ø–∏–∫–µ—Ä–∞–º–∏
"""

from typing import List, Dict, Optional
from dataclasses import dataclass
import os
from pyannote.audio import Pipeline
import torch
import torchaudio


@dataclass
class SpeakerSegment:
    """–°–µ–≥–º–µ–Ω—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–ø–∏–∫–µ—Ä–µ"""
    start: float  # –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    end: float    # –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    speaker: str  # –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–ø–∏–∫–µ—Ä–∞ ('SPEAKER_00', 'SPEAKER_01', etc.)
    
    def to_dict(self) -> Dict:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            'start': self.start,
            'end': self.end,
            'speaker': self.speaker
        }


class SpeakerDiarizer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ –≤ –∞—É–¥–∏–æ"""
    
    def __init__(
        self,
        hf_token: str,
        device: Optional[str] = None,
        pipeline_name: str = "pyannote/speaker-diarization-3.1"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è diarizer
        
        Args:
            hf_token: HuggingFace access token
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ('cpu', 'cuda' –∏–ª–∏ None –¥–ª—è –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
            pipeline_name: –ù–∞–∑–≤–∞–Ω–∏–µ pipeline –Ω–∞ HuggingFace Hub
            
        –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:
            –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è pyannote.audio –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:
            1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ HuggingFace (https://huggingface.co)
            2. –ü–æ–ª—É—á–∏—Ç—å access token (https://huggingface.co/settings/tokens)
            3. –ü—Ä–∏–Ω—è—Ç—å —É—Å–ª–æ–≤–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π:
               - https://huggingface.co/pyannote/speaker-diarization-3.1
               - https://huggingface.co/pyannote/segmentation-3.0
        """
        if not hf_token or hf_token == "your_huggingface_token_here":
            raise ValueError(
                "–ù–µ–æ–±—Ö–æ–¥–∏–º HuggingFace access token!\n"
                "1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ https://huggingface.co\n"
                "2. –°–æ–∑–¥–∞–π—Ç–µ —Ç–æ–∫–µ–Ω: https://huggingface.co/settings/tokens\n"
                "3. –ü—Ä–∏–º–∏—Ç–µ –ª–∏—Ü–µ–Ω–∑–∏–∏ –º–æ–¥–µ–ª–µ–π:\n"
                "   - https://huggingface.co/pyannote/speaker-diarization-3.1\n"
                "   - https://huggingface.co/pyannote/segmentation-3.0\n"
                "4. –£–∫–∞–∂–∏—Ç–µ —Ç–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ –∏–ª–∏ –ø–µ—Ä–µ–¥–∞–π—Ç–µ –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä"
            )
        
        self.hf_token = hf_token
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        if device is None:
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.device = torch.device(device)
        
        print(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ pyannote.audio pipeline –Ω–∞ {device}...")
        print(f"   –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–µ–π: ~1.5 GB")
        print(f"   –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ...")
        
        try:
            from tqdm import tqdm
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pipeline —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
            with tqdm(total=100, desc="–ó–∞–≥—Ä—É–∑–∫–∞ pyannote", bar_format='{l_bar}{bar}| {n_fmt}%') as pbar:
                pbar.update(10)
                # –í –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ pyannote.audio –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 'token' –≤–º–µ—Å—Ç–æ 'use_auth_token'
                try:
                    self.pipeline = Pipeline.from_pretrained(
                        pipeline_name,
                        token=hf_token
                    )
                except TypeError:
                    # –î–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π
                    self.pipeline = Pipeline.from_pretrained(
                        pipeline_name,
                        use_auth_token=hf_token
                    )
                pbar.update(70)
                
                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                self.pipeline.to(self.device)
                pbar.update(20)
            
            print(f"‚úì Pipeline pyannote.audio –∑–∞–≥—Ä—É–∂–µ–Ω!")
            
        except Exception as e:
            error_msg = str(e)
            if "401" in error_msg or "unauthorized" in error_msg.lower():
                raise RuntimeError(
                    "–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ HuggingFace!\n"
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n"
                    "1. –¢–æ–∫–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π?\n"
                    "2. –í—ã –ø—Ä–∏–Ω—è–ª–∏ –ª–∏—Ü–µ–Ω–∑–∏–∏ –º–æ–¥–µ–ª–µ–π?\n"
                    "   - https://huggingface.co/pyannote/speaker-diarization-3.1\n"
                    "   - https://huggingface.co/pyannote/segmentation-3.0"
                )
            else:
                raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ pipeline: {error_msg}")
    
    def diarize(
        self,
        audio_file: str,
        min_speakers: Optional[int] = None,
        max_speakers: Optional[int] = None,
        num_speakers: Optional[int] = None
    ) -> List[SpeakerSegment]:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤ –≤ –∞—É–¥–∏–æ —Ñ–∞–π–ª–µ
        
        Args:
            audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            min_speakers: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            max_speakers: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            num_speakers: –¢–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å–æ —Å–ø–∏–∫–µ—Ä–∞–º–∏
            
        –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:
            –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, pipeline –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        """
        if not os.path.exists(audio_file):
            raise FileNotFoundError(f"–ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file}")
        
        print(f"üé§ –ù–∞—á–∏–Ω–∞–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤...")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è pipeline
        params = {}
        if num_speakers is not None:
            params['num_speakers'] = num_speakers
            print(f"   –û–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {num_speakers}")
        elif min_speakers is not None or max_speakers is not None:
            if min_speakers is not None:
                params['min_speakers'] = min_speakers
                print(f"   –ú–∏–Ω–∏–º—É–º —Å–ø–∏–∫–µ—Ä–æ–≤: {min_speakers}")
            if max_speakers is not None:
                params['max_speakers'] = max_speakers
                print(f"   –ú–∞–∫—Å–∏–º—É–º —Å–ø–∏–∫–µ—Ä–æ–≤: {max_speakers}")
        else:
            print("   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
        
        # –ó–∞–ø—É—Å–∫ diarization —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
        from tqdm import tqdm
        
        try:
            print("   –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ –≤ –ø–∞–º—è—Ç—å...")
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –ø–∞–º—è—Ç—å (–æ–±—Ö–æ–¥ –ø—Ä–æ–±–ª–µ–º—ã —Å AudioDecoder –Ω–∞ Windows)
            waveform, sample_rate = torchaudio.load(audio_file)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–æ–Ω–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–º–∏
            audio_in_memory = {
                "waveform": waveform,
                "sample_rate": sample_rate
            }
            
            print("   –ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ...")
            with tqdm(total=100, desc="Diarization", bar_format='{l_bar}{bar}| {n_fmt}%') as pbar:
                pbar.update(10)
                diarization = self.pipeline(audio_in_memory, **params)
                pbar.update(90)
        except Exception as e:
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Å–ø–∏–∫–µ—Ä–æ–≤: {str(e)}")
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
        print("   –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        
        segments = []
        
        # pyannote.audio 4.0+ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DiarizeOutput dataclass
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        if hasattr(diarization, 'segments'):
            # –ü—Ä—è–º–æ–π —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            for seg in diarization.segments:
                segments.append(
                    SpeakerSegment(
                        start=seg.start,
                        end=seg.end,
                        speaker=seg.speaker
                    )
                )
        elif hasattr(diarization, 'diarization'):
            # –í–ª–æ–∂–µ–Ω–Ω—ã–π Annotation –æ–±—ä–µ–∫—Ç
            annotation = diarization.diarization
            for segment, track, label in annotation.itertracks(yield_label=True):
                segments.append(
                    SpeakerSegment(
                        start=segment.start,
                        end=segment.end,
                        speaker=label
                    )
                )
        else:
            # –î–ª—è dataclass —Å –ø–æ–ª—è–º–∏ (pyannote.audio 4.0+)
            import dataclasses
            if dataclasses.is_dataclass(diarization):
                # –ò—â–µ–º –ø–æ–ª–µ —Å Annotation –¥–∞–Ω–Ω—ã–º–∏
                for field in dataclasses.fields(diarization):
                    value = getattr(diarization, field.name)
                    if hasattr(value, 'itertracks'):
                        for segment, track, label in value.itertracks(yield_label=True):
                            segments.append(
                                SpeakerSegment(
                                    start=segment.start,
                                    end=segment.end,
                                    speaker=label
                                )
                            )
                        break
            else:
                # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –ø—Ä—è–º–æ–π Annotation –æ–±—ä–µ–∫—Ç
                for segment, track, label in diarization.itertracks(yield_label=True):
                    segments.append(
                        SpeakerSegment(
                            start=segment.start,
                            end=segment.end,
                            speaker=label
                        )
                    )
        
        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤
        unique_speakers = sorted(set(seg.speaker for seg in segments))
        
        print(f"‚úì –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"  ‚îî‚îÄ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {len(unique_speakers)}")
        print(f"  ‚îî‚îÄ –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segments)}")
        
        return segments
    
    def diarize_with_stats(
        self,
        audio_file: str,
        **kwargs
    ) -> tuple[List[SpeakerSegment], Dict]:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—Å–µ–≥–º–µ–Ω—Ç—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
        """
        segments = self.diarize(audio_file, **kwargs)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        unique_speakers = sorted(set(seg.speaker for seg in segments))
        
        # –û–±—â–µ–µ –≤—Ä–µ–º—è –≥–æ–≤–æ—Ä–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
        speaker_duration = {}
        for speaker in unique_speakers:
            total_time = sum(
                seg.end - seg.start 
                for seg in segments 
                if seg.speaker == speaker
            )
            speaker_duration[speaker] = total_time
        
        stats = {
            'num_speakers': len(unique_speakers),
            'speakers': unique_speakers,
            'num_segments': len(segments),
            'speaker_duration': speaker_duration,
            'total_duration': segments[-1].end if segments else 0.0
        }
        
        return segments, stats
    
    def get_speaker_timeline(self, segments: List[SpeakerSegment]) -> Dict[str, List[tuple]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –ª–∏–Ω–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
        
        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å–æ —Å–ø–∏–∫–µ—Ä–∞–º–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å {speaker: [(start, end), ...]}
        """
        timeline = {}
        for segment in segments:
            if segment.speaker not in timeline:
                timeline[segment.speaker] = []
            timeline[segment.speaker].append((segment.start, segment.end))
        
        return timeline


def diarize_audio(
    audio_file: str,
    hf_token: str,
    num_speakers: Optional[int] = None,
    device: Optional[str] = None
) -> List[SpeakerSegment]:
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤
    
    Args:
        audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
        hf_token: HuggingFace access token
        num_speakers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ('cpu' –∏–ª–∏ 'cuda')
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å–æ —Å–ø–∏–∫–µ—Ä–∞–º–∏
    """
    diarizer = SpeakerDiarizer(hf_token=hf_token, device=device)
    return diarizer.diarize(audio_file, num_speakers=num_speakers)
